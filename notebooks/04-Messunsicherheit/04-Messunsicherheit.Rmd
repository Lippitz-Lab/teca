# Messunsicherheit


```{r , echo=FALSE}
folder = "04-Messunsicherheit/"
```



[Ziel:]{.smallcaps} Ich kann verschiedene Arten von Messunsicherheiten
*unterscheiden*, sowie den Formalismus ihrer Zusammenführung *erklären*
und *anwenden*.

-   Bayes Statistik und die Bedeutung von 'Wahrscheinlichkeit': Abzählen
    von Ereignissen oder Unwissen.

-   Formalismus des 'Guide to the expression of uncertainty in
    measurement' (GUM)

-   Kombination von Unsicherheiten, auch bekannt als Fehlerfortpflanzung

[Literatur:]{.smallcaps} Stahel Kap. 4, Tschirk Kap. 2 & 7, Kirkup &
Frenkel Kap.4--10, Schenk & Kremer Kap. EF.3

## Fehler und Unsicherheiten

Es ist sinnvoll, zwischen Fehlern und Unsicherheiten zu unterscheiden.
Fehler sollte man vermeiden. Unsicherheiten sind nie zu vermeiden,
können aber reduziert werden.

##### Grobe Fehler

sind beispielsweise offensichtliche Fehlbedienungen des Messgeräts und
manifestieren sich durch eine deutliche Abweichung des gemessenen Werts
vom erwarteten Messwert. Solche Fehler sollte man natürlich vermeiden.
Falls sie doch auftreten und bemerkt werden, dann wiederholt man
wahrscheinlich am einfachsten die Messung oder schließt zumindest diesen
Messwert von der weiteren Analyse aus.

##### Systematische Fehler

sind eine Umschreibung dafür, dass der Messprozess nicht ganz so
einfach, so ideal ist, wie man zunächst denken könnte. Eine Waage zeigt
einen von Null verschiedenen Wert an, auch wenn keine Masse aufgelegt
ist. Ein Maßstab dehnt nicht mit der Temperatur aus. Diese und ähnliche
Komplikationen berücksichtigt man durch eine passende Erweiterung des
Modells, das die Messung beschreibt. Danach sollten diese Fehler keine
Rolle mehr spielen, falls doch, dann beschreiben systematische Fehler
mangelndes Verständnis des Messprozesses und sind häufig erst im
Rückblick zu erkennen. Gute Experimente zeichnen sich dadurch aus, dass
systematische Fehler vollständig behandelt werden.

##### Unsicherheiten

sind aber nie zu vermeiden. Sie können verschiedene Ursachen habe. Jede
Waage zeigt das Gewicht nur mit einer endlichen Anzahl Stellen an,
beispielsweise $m=12,3$g. Das wahre Gewicht kann damit aber immer noch
im Intervall $12.25$g -- $12.35$g liegen. Wiederholte Messungen unter
konstanten Bedingungen können abweichende, leicht schwankende Ergebnisse
liefern. Dieses Rauschen ist ein Zeichen dafür, dass die Bedingungen
technisch oder auch grundsätzlich nicht exakt kontrolliert werden
können. Wieviel Atome in der nächsten Sekunde einen Alpha-Zerfall machen
unterliegt nicht unserer Kontrolle.

Wie beschreibt man nun solche Unsicherheiten? Welchen Einfluss haben
Unsicherheiten der Messgrößen auf daraus berechnete Werte? Wie
berücksichtigt man dabei Unsicherheiten, die man selbst bestimmt, und
solche, die beispielsweise in Datenblättern dokumentiert sind? Person A
entwickelt eine Waage und dokumentiert deren Unsicherheit. Person B
benutzt diese Waage, um die Dichte von Ethanol zu messen, und
dokumentiert die Unsicherheit in der Dichte. Person C benutzt diese
gemessene Dichte (und deren Unsicherheit), um die Viskosität (und deren
Unsicherheit) zu bestimmen. Unsicherheiten müssen also konsistent und
vergleichbar dokumentiert werden, und es muss ein Verfahren geben,
Unsicherheiten aus verschiedenen Quellen in ein Berechnung einfließen zu
lassen.

Ein solches Verfahren wird im 'Guide to the Expression of Uncertainty in
Measurementt' (GUM) des Bureau International des Poids es Mesures
beschrieben und ist Industriestandard in der Metrologie. Es
standardisiert und modifiziert damit teilweise das, was in der Physik
unter 'Fehlerrechnung' verstanden wurde. Ein wesentlicher Punkt ist,
dass systematische Fehler gar nicht betrachtet werden (diese sind ja zu
vermeiden) und Unsicherheiten nach dem Weg zu ihrer Bestimmung als Typ A
(statistisch) und Typ B (Datenblatt) klassifiziert werden. Der
wissenschafts-philosophisch interessante Punkt ist die gleichberechtigte
Behandlung und Zusammenfassung dieser beiden Typen Unsicherheiten.
Unsicherheiten von Typ A benutzen den Wahrscheinlichkeitsbegriff der
klassischen Statistik (frequentistisch, also durch Abzählen bestimmt).
Typ B Unsicherheiten sind geprägt von dem Bayes'schen
Wahrscheinlichkeitsbegriff, der den Grad unserer persönlichen
Überzeugung, unseres Wissens beschreibt. Die meisten Wissenschaftler
lösen dieses Problem pragmatisch, ebenso wie der GUM, und ignorieren
diesen Unterschied außerhalb philosophischer Diskussionen.

Folgende Quellen beschreiben GUM

JCGM 100:2008

:   Dokument 100 aus dem Jahr 2008 des Joint Committee for Guides in
    Metrology mit dem Titel 'Evaluation of measurement data --- Guide to
    the expression of uncertainty in measurement'. Dies ist der zentrale
    Text mit vielen Anhängen, allerdings nicht einfach zu lesen.

JCGM 104:2009

:   Dokument 104 aus dem Jahr 2009 des Joint Committee for Guides in
    Metrology mit dem Titel 'Evaluation of measurement data -- An
    introduction to the \"Guide to the expression of uncertainty in
    measurement\" and related documents'. Von diesem Text gibt es auch
    eine deutsche Übersetzung. Diese EInführung ist etwas besser zu
    lesen als \[JCGM 100:2008\], aber immer noch sehr formal
    geschrieben.

Kirkup / Frenkel

:   Das Buch 'An Introduction to Uncertainty in Measurement using the
    GUM' von Les Kirkup und Bob Frenkel gibt auf ca. 200 Seiten eine
    sehr gut lesbare Einführung in dieses Thema. Hier werden auch alle
    Beziehungen hergeleitet, auf die in diesem Tutorial nur verwiesen
    wird. Auch zeigen die Autoren viele Beispiele.

## Bestimmung der Messunsicherheit

```{r 04-workflow-std, echo=FALSE, fig.cap = "Schema zur Bestimmung der Messunsicherheit nach GUM, aus JCGM104:2009, dt", out.width='100%'}
knitr::include_graphics(paste(folder, "workflow_std.png", sep=""))
```


Als erstes betrachten wir das Verfahren, mit dem nach GUM die
Messunsicherheit eines Ergebnisses aus den Standard-Abweichungen der
Eingangswerte berechnet wird. Dies ist sehr nahe an der traditionellen
Fehlerrechnung. Abbildung \@ref(fig:04-workflow-std) zeigt ein Schema dieses Verfahrens. Dieses
Verfahren wird dann in den folgenden Kapiteln durch Einführung des
Überdeckungsintervalls und Verallgemeinerung auf andere
Wahrscheinlichkeitsverteilungen als die Normalverteilung erweitert.

### Messfunktion

Selten interessiert der gemessene Wert direkt, sondern verschiedene
gemessene Werte sollen zu einem Ausgangswert verknüpft werden. Man
bestimmt beispielsweise Masse und Geschwindigkeit, um daraus die
kinetische Energie zu berechnen. Diesen Zusammenhang zwischen den
Eingangswerten $X_i$ und dem Ausgangswert $Y$ beschriebt die
Messfunktion $$Y = f(X_1, ... , X_n) \quad.$$ Dabei bezeichnen große
Buchstaben jeweils den 'wahren', idealen Wert, der nie gemessen sondern
immer nur geschätzt werden kann. Die Messfunktion $f$ beruht immer
direkt auf den gemessenen Größen, nicht auf Zwischenergebnissen, da nur
so berücksichtigt werden kann, wenn eine Messung an verschiedenen
Stellen der Funktion eingeht, und so ihre Fehler korreliert sind. Auch
umfasst die Messfunktion nicht nur den idealen, 'Lehrbuch-artigen'
Zusammenhang zwischen Messgrößen und Ausgangswert, sondern auch alle
Korrekturen, die notwendig sind, um systematische Fehler zu beseitigen.
Im Beispiel der kinetischen Energie wäre dies also nicht
$$E = \frac{1}{2} \, m \, v^2 \quad \quad \text{(kleine Buchstaben hier aus Gewohnheit)}$$
sondern beispielsweise
$$E = \frac{1}{2} \, \alpha (m  - m_0) \, \left( \frac{ \beta (L - L_0)}{\gamma (t_1 - t_2)} \right)^2
\quad .$$ Dabei berücksichtigen die Faktoren $\alpha, \beta, \gamma$ die
Abweichung in der Kalibration der Masse-, Länge- und Zeit-Messung, sowie
$m_0$ und $x_0$ die Abweichung der Nullpunktslage.

### Schätzwerte der Eingangswerte

Die 'wahren' Eingangswerte $X_i$ der Messfunktion kennt man nie. Man
kann sich aber Schätzwerte $x_i$ dieser Werte beschaffen. Notfalls ist
der Wert der einzigen Messung der Schätzwert $x_i$. Wenn eine Messung
mehrmals unter identischen Bedingungen wiederholt durchgeführt werden
kann, dann ist der Mittelwert aus diesem Datensatz ein guter Schätzwert.
Auch schriftliche Aufzeichnungen wie Datenblätter liefern Schätzwerte
der Eingangswerte. Die oben genannten Faktoren $\alpha, \beta, \gamma$
zur Abweichung in der Kalibration werden wohl typischerweise mit dem
Wert Eins geschätzt, falls nicht ein Gerät fehl-kalibriert ist.

### Schätzwert des Ergebnisses

Den Schätzwert des Ergebnisses $y$ erhält man, in dem man die
Schätzwerte der Eingangswerte $x_i$ in die Messfunktion einsetzt
$$y = f(x_1, ... , x_n) \quad .$$ Der hier beschriebe Formalismus
behandelt also nur ein Ergebnis pro Experiment. Wenn zwei oder mehr
Ergebnisse aus einem gemeinsamen Datensatz gewonnen werden sollen, dann
würde auch die Kovarianz dieser Ergebnisse interessieren. Dies ist ein
fortgeschritteneres Thema, ebenso wie hier ebenso nicht berücksichtige
Kovarianzen zwischen den Eingangswerten $x_i$.

### Standard-Messunsicherheit der Eingangswerte

Die Standard-Messunsicherheit $u(x_i)$ eines Eingangswerte $x_i$ ist die
Standard-Abweichung seiner Wahrscheinlichkeitsverteilung. Man muss also
durch Messen (Typ A) oder andere Quellen (Typ B) die
Wahrscheinlichkeitsverteilung bestimmen und daraus dann die
Standard-Abweichung.

##### Typ A: Wahrscheinlichkeitsverteilung messen
Unsicherheiten vom Typ A werden durch statistische Methoden ermittelt.
Beispielsweise wird eine Messung wiederholt durchgeführt. Als Wert des
Größe kann dann der Mittelwert dieser Messungen dienen, als Unsicherheit
die Standardabweichung der Einzelmessung oder des Mittelwerts.
Aufwändigere Auswerteverfahren sind denkbar, beispielsweise um eine
darunter liegende Drift zu bereinigen oder eine Größe und deren
Unsicherheit per Regression zu bestimmen. Zentral sind hier aber die
statistischen Methoden, die Auswertung eines Datensatzes.

Wiederholte, unabhängige Messungen $x_{i,k}$ bei ansonsten konstanten
Bedingungen liefern die Wahrscheinlichkeitsverteilung und somit $u(x_i)$
$$u(x_i) = \sqrt{\frac{1}{n -1}  \, \sum_{k= 1}^{n} \left( x_{i,k} - \bar{x_i} \right)^2} 
\quad \text{mit} \quad 
\bar{x_i}= \frac{1}{n}  \, \sum_{k= 1}^{n}  x_{i,k}$$ Ebenso liefert die
lineare Regression oder andere Methoden der kleinsten Quadrate eine
Standard-Abweichung und somit die Messunsicherheit.

##### Typ B: Wahrscheinlichkeitsverteilung aus anderen Quellen
Unsicherheiten vom Typ B sind nicht über statistische Methoden
zugänglich. Beispiele sind die endliche Auflösung einer Waage oder die
tabellierte Messunsicherheit eines Multimeters. In diesen Fällen
bestimmt man die Spannung über einem Widerstand eben nicht mit 10
verschiedenen Multimetern und benutzt dann Statistik. um Aussagen zu
treffen, sondern man benutzt aufgeschriebene, dokumentierte Angaben zur
Unsicherheit. Diese Art Unsicherheit beschreibt nicht das Ergebnis von
Abzähl-Prozessen, sondern unser Nicht-Wissen über den 'wahren' Wert.
Natürlich liegt dieser aufgeschriebenen Unsicherheit ein Messprozess,
eine Kalibration zu grunde, die aber nicht von uns, sondern vom
Hersteller durchgeführt wurde. Das Erstellen des Datenblatts durch den
Hersteller verwandelt also Typ A Unsicherheiten in Typ B Unsicherheiten.
Das Ziel des GUM ist, dies so zu gestalten, dass beide Arten von
Unsicherheiten später wieder miteinander verrechnet werden können.

Typische andere Quellen sind Datenblätter, Kalibrationsdokumente, aber
auch Fachkenntnis. Aus diesen wird dann die Standard-Messunsicherheit
berechnet.

##### Angegebene Wahrscheinlichkeitsverteilung

Idealerweise ist die vollständige Wahrscheinlichkeitsverteilung
angegeben, die der Hersteller eines Geräts sicherlich im
Kalibrationsprozess einmal ermittelt hat. In diesem Fall berechnen wir
die Standard-Messunsicherheit als Standard-Abweichung dieser Verteilung.

##### Überdeckungsintervall

Das Überdeckungsintervall $[-a, a]$ gibt einen Bereich an, in dem der
'wahre' Wert mit angegebener Wahrscheinlichkeit (meist 95%) zu finden
ist. Kapitel XXX beschäftigt sich mit der Berechnung dieses Intervalls.
Hier ermitteln wir daraus die Standard-Messunsicherheit, indem wir eine
Normalverteilung annehmen. Im Fall eines 95%-Intervalls ($2 \sigma$)
beträgt sie $u = a /2$.

##### Toleranz

Bei manchen Geräten, beispielsweise Multimetern, ist eine Toleranz in
der Form $a = n$ digits $+ x$% des Vollausschlags angegeben. Der 'wahre'
Wert sollte also in einem Intervall der Breite $[-a, a]$ liegen. Solch
eine rechteckige Verteilung hat die Standard-Abweichung
$u = a / \sqrt{3}$.

##### Ablesen digitaler Anzeigen

Selbst wenn keine Toleranz angegeben ist, so gilt doch mindestens
$a = 0.5$ digits, da keine Aussage über nicht dargestellte Stellen
gemacht werden kann. Somit wird hier ebenfalls $u = a / \sqrt{3}$.

##### Fachkenntnis

Das Zählen einzelner Ereignisse, beispielsweise die Anzahl Photonen in
einem Lichtstrahl, liefert oft eine Poisson-Verteilung. Bei einem
Mittelwert von $\lambda$ ist in diesem Fall die
Standard-Messunsicherheit $u = \sqrt{\lambda}$.

##### Kombination beider Fälle {#sec:kombinationAB}

Man sollte auch prüfe, ob nicht beide Quellen A und B zur
Messunsicherheit beitragen. Wenn beispielsweise die Standard-Abweichung
aus mehreren Messungen nach Typ A bestimmt wird, jede Einzelmessung aber
eine nicht zu vernachlässigende Messunsicherheit nach Typ B hat. In
diesem Fall addieren sich die Varianzen. Für die
Standard-Messunsicherheit gilt also
$$u_{\text{gesamt}} = \sqrt{ u_{A}^2  + u_{B}^2 } \quad .$$ Als
Daumenregel kann man annehmen, dass dieser Fall relevant wird, wenn das
Verhältnis der beiden Messunsicherheiten kleiner als drei ist.

##### Unsicherheit der Einzelmessung oder des Mittelwerts

An dieser Stelle können wir jetzt auch diskutieren, ob bei der
Messunsicherheit nach Typ A eigentlich die Unsicherheit der
Einzelmessung $u_{\text{einzel}}$ oder die des Mittelwerts aus $n$
Messungen, also $u_{\text{mittel}} = u_{\text{einzel}} / \sqrt{n}$,
relevant ist.

Mit der Reduktion der Messunsicherheit über Mittelwertbildung muss man
sehr vorsichtig sein. Sie verlangt, dass alle einzelnen Messungen
unabhängig voneinander sind. Dies ist beispielsweise nicht mehr der
Fall, wenn eine Drift die gesamte Messung überlagert, oder die einzelnen
Messungen schneller erfolgte, als die Messbandbreite erlaubt. Selbst im
idealen Fall reduziert die Mittelwertbildung zwar die Unsicherheit nach
Typ A, aber nicht die nach Typ B, so dass irgendwann Typ B überwiegt,
wie in Abschnitt [2.4.3](#sec:kombinationAB){reference-type="ref"
reference="sec:kombinationAB"} dargestellt.

### Empfindlichkeits-Koeffizienten

Um den Einfluss der Messunsicherheit der Eingangswerte auf den
Ausgangswert zu ermitteln, betrachtet man die partielle Ableitung der
Messfunktion $Y = f(X_1, ... , X_n)$ nach den 'wahren' Werten $X_i$ an
der Stelle des Schätzwerts der Eingangswerte $x_i$. Man entwickelt also
$f$ in einer Taylor-Reihe und bricht diese bereits nach dem ersten Glied
ab. Man linearisiert also $f$ in der Nähe der $x_i$. Die einzelnen
Koeffizienten dieser Taylor-Reihe, die partiellen Ableitungen, werden in
diesem Zusammenhang Empfindlichkeits-Koeffizienten genannt
$$c_i = \left. \frac{\partial f(X_1, ... , X_n) }{\partial X_i} \right|_{X_1 = x_1, ... , X_n = x_n} \quad .$$
Es ist hilfreich, die Größenordnung der Produkte aus Messunsicherheit
$u(x_i)$ und Empfindlichkeits-Koeffizient $c_i$, also $|c_i| u(x_i)$, zu
betrachten. Im idealen Fall sind diese alle von gleicher Größenordnung.
Wenn nicht, dann lohnt es sich, Arbeit in den größten Term zu
investieren. Entweder um dort die Messunsicherheit $u(x_i)$ zu
reduzieren, oder das Messverfahren so zu ändern, dass sich $f$ so
ändert, dass $|c_i|$ kleiner wird. Der relative Beitrag von
$|c_i| u(x_i)$, also $$\frac{|c_i| u(x_i)}{\sum_k |c_k| u(x_k)}$$ wird
Messunsicherheits-Budget genannt.

### Standard-Messunsicherheit des Ergebnisses

Die Standard-Messunsicherheit des Ergebnisses ergibt sich analog der
Gauss'schen Fehlerfortpflanzung zu
$$u(y) = \sqrt{ \left( c_1 u(x_1) \right)^2  + ... +  \left( c_n u(x_n) \right)^2    }
 \quad .$$

## Überdeckungsintervall

Im vorangegangenen Kapitel haben wir einen Schätzwert für den
Ausgangswert $y$ der Messung sowie für seine Standard-Messunsicherheit
$u(y)$ ermittelt. Die Frage ist jetzt, welche Aussage wir über den
'wahren' Wert $Y$ machen können. Das Ziel ist es, ein Intervall
anzugeben, in dem der 'wahre' Wert $Y$ mit einer bestimmten
Wahrscheinlichkeit liegt. Dieses Intervall wird Überdeckungsintervall
genannt.

Das Problem ist, dass wir insbesondere von der Messunsicherheit $u(y)$
nur einen Schätzwert haben. Dass $y$ nur ein Schätzwert von $Y$ ist,
stellt kein Problem dar, denn wir kennen die
Wahrscheinlichkeitsverteilung des Abstandes $y - Y$. Diese Abstand ist
normalverteilt
$$\frac{y - Y}{\sigma  /\sqrt{n}} = \mathcal{N}(0,1) \quad .$$ Dies
setzt aber voraus, dass man den 'wahren' Wert der Standardabweichung
$\sigma$ kennt. $n$ bezeichnet hier die Anzahl der Werte, aus denen $y$
ermittelt wurde.

Falls statt dem 'wahren' Wert $\sigma$ nur der Schätzwert $u(y)$ bekannt
ist, dann folgt der normierte Abstand $y-Y$ einer Student'sche
t-Verteilung, die im Grenzwert großer $n$ in die Normalverteilung
übergeht $$\frac{y - Y}{u(y)  /\sqrt{n}} = t_n  \quad 
 \overset{n \rightarrow \infty}{\longrightarrow} \quad
 \mathcal{N}(0,1) \quad .$$ Die Student'sche t-Verteilung besitzt die
Wahrscheinlichkeitsdichte
$$t_n(x) = \alpha \left(1 + \frac{x^2}{n} \right)^{- (n+1)/2}$$ wobei
der Faktor $\alpha$ die Normierung sicherstellt. Diese Verteilung wird
es uns ermöglichen, ein Überdeckungsintervall anzugeben.

(ref:foo) A scatterplot of the data `cars` using **base** R graphics. 

```{r foo, fig.cap='(ref:foo)'}
plot(cars)  # a scatterplot
```

```{r 04-workflow-ausf, echo=FALSE, fig.cap="Schema zur Bestimmung des Überdeckungsintervalls  nach GUM, aus JCGM104:2009, dt. Der linke obere Bereich wurde schon im vorangegangenen Kapitel in Abbildung \\@ref(fig:04-workflow-std) besprochen", out.width='100%'}
knitr::include_graphics(paste(folder, "workflow_ausf.png", sep=""))
```

\@ref(fig:04-workflow-std)


### Freiheitsgrade

Der Freiheitsgrad $\nu_i$ beschreibt die Anzahl an Einzelmessungen, die
zu einem Schätzwert $x_i$ eines Eingangswerts $X_i$ beigetragen haben.
Er ist ein Maß für das Vertrauen in die Schätzung der
Standard-Messunsicherheit $u(x_i)$.

Für Messunsicherheiten vom *Typ A* gilt
$$\nu_i = \text{<Anzahl Messungen>} - \text{<Anzahl ermittelte Parameter>}  \quad .$$
Wenn aus $n$ Messungen der Schätzwert $x_i$ als Mittelwert berechnet
wurde, so ist $\nu_i = n -1$. Damit ist $\nu_i = 0$, falls nur ein Wert
gemessen wurde. Bei einer lineare Regression werden beispielsweise
Steigung und Achsenabschnitt ermittelt, frei gelassen, also zwei
Parameter bestimmt. Wenn nun $x_i$ aus der Steigung bestimmt wird, so
ist $\nu_i = n -2$, da die Information aus einer weiteren Messung schon
für den Achsenabschnitt verwendet wurde.

Für Messunsicherheiten vom *Typ B* ist manchmal die mit dieser
Unsicherheit verknüpften Anzahl an Freiheitsgraden $\nu$ ebenfalls
tabelliert. Wenn das nicht der Fall ist, dann lässt sich Überlegungen
zur Varianz der Varianz einer Normalverteilung folgende Beziehung
herleiten
$$\nu_i = \frac{1}{2} \left( \frac{\Delta u(x_i)}{u(x_i)} \right)^{-2}$$
wobei $\Delta u(x_i)$ die Unsicherheit in der Unsicherheit des
Eingangswerts $x_i$ bezeichnet. $\Delta u(x_i)$ ergibt sich
beispielsweise aus der Anzahl der dargestellten Stellen bei tabelliert
$u(x_i)$. Oder man nimmt an, dass das bei einem Multimeter angegeben
Toleranz-Intervall so groß ist, dass außerhalb liegende Werte praktisch
unmöglich sind. In diesem Fall ist die die Unsicherheit exakt bekannt,
damit $\Delta u(x_i) = 0$ und $\nu_i = \infty$. Dies stellt kein Problem
dar.

### Effektive Freiheitsgrade

Wir kennen nun die Freiheitsgrade $\nu_i$ der Eingangsgrößen. Wir
benötigen aber die Freiheitsgrade der Ausgangsgröße bzw. ihrer
Messunsicherheit, um den Faktor in der Student'schen t-Verteilung (Tab
[3.2](#tab:student-t){reference-type="ref" reference="tab:student-t"})
nachzuschlagen. Die Welch--Satterthwaite-Gleichung liefert eine
Abschätzung für die effektive Anzahl an Freiheitsgraden
$\nu_{\text{eff}}$, die der Messunsicherheit $u(y)$ des Ausgangsgröße
$y$ zugeordnet werden kann:
$$\nu_{\text{eff}} = \frac{u(y)^4}{\sum_{i=1}^n \frac{c_i^4 \, u(x_i)^4}{\nu_i}}
\ll \sum_{i=1}^n \nu_i
 \quad  .$$ Dabei wird $\nu_{\text{eff}}$ auf die nächste ganze Zahl
abgerundet. Wenn eine Eingangsgröße $x_k$ entweder eine große
Standard-Messunsicherheit $c_k u(x_k)$ besitzt oder eine kleine Anzahl
Freiheitsgrade $\nu_k$ oder beides, dann dominiert diese Größe die
Anzahl der effektiven Freiheitsgrade $\nu_{\text{eff}} \approx \nu_k$.

### Überdeckungswahrscheinlichkeit

Man muss sich für eine Wahrscheinlichkeit entscheiden, mit der der
'wahre' Wert in dem Überdeckungsintervall liegen soll. Typische Werte
(Tab. [3.1](#tab:ksigma){reference-type="ref" reference="tab:ksigma"}),
sind verknüpft mit den Integralen über die Normalverteilung innerhalb
einer $\pm k \cdot \sigma$ Umgebung, oder gerundete Werte davon. Am
häufigsten findet sich das 95% Intervall.

::: {#tab:ksigma}
  $k$   $P$        $P$   $k$
  ----- ------- -- ----- -------
  1     68,27      66    ??
  2     95,45      95    1,960
  2     99,73      99    2,576

  : Wahrscheinlichkeit $P$ in Prozent, bei einer Normalverteilung
  innerhalb einer $k \sigma$ Umgebung zu liegen. Das 95% Intervall mit
  $k=1.96$ ist am weitesten verbreitet. [\[tab:ksigma\]]{#tab:ksigma
  label="tab:ksigma"}
:::

### Erweiterungsfaktor

Der Erweiterungsfaktor $k$ bestimmt die Grenzen des
Überdeckungsintervalls, in dem der 'wahre' Wert mit der gewünschten
Wahrscheinlichkeit zu finden ist. Das Intervall hat dann die Form
$[y - k \cdot u(y), y + k \cdot u(y)]$. Der Wert von $k$ ergibt sich aus
dem Integral über die Student'sche t-Verteilung, so dass
$$\int_{- k}^{+ k} t_\nu(x) dx = \text{gewünschte Wahrscheinlichkeit} \quad .$$
Diese Wert hängt natürlich von der Anzahl $\nu_{\text{eff}}$ der
effektiven Freiheitsgrade ab, die in die Messung eingeflossen sind. Für
sehr großes $\nu_{\text{eff}}$ nimmt $k$ die bekannten Werte aus der
Normalverteilung an. Einige andere Werte finden sich in Tabelle
[3.2](#tab:student-t){reference-type="ref" reference="tab:student-t"},
im Anhang G2 von GUM, sowie im Internet.

::: {#tab:student-t}
    $\nu$        1       2       3       4       5      10      20   $\infty$
  ------- -------- ------- ------- ------- ------- ------- ------- ----------
      $k$   12,706   4,303   3,182   2,776   2,571   2,228   2,086      1,960

  : Erweiterungsfaktor $k$ des 95%-Intervalls der Student'schen
  t-Verteilung in Abhängigkeit von der Anzahl der Freiheitsgrade
  $\nu$.[\[tab:student-t\]]{#tab:student-t label="tab:student-t"}
:::

### Erweiterte Messunsicherheit

Die erweiterte Messunsicherheit ist die Standard-Messunsicherheit $u(y)$
multipliziert mit dem Erweiterungsfaktor $k$
$$U = k \cdot u(y) \quad .$$

### Überdeckungsintervall

Das Überdeckungsintervall beträgt $[y \pm U]$ =
$[y - k \cdot u(y), y + k \cdot u(y)]$. Der 'wahre' Werte $Y$ liegt in
diesem Intervall mit der oben festgelegten Wahrscheinlichkeit.

## Andere Wahrscheinlichkeitsverteilungen und Monte-Carlo-Simulationen

comming soon \...
